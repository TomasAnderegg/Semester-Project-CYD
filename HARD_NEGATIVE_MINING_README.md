# Guide d'utilisation de Hard Negative Mining

## ğŸ“š Qu'est-ce que Hard Negative Mining?

Hard Negative Mining est une technique d'Ã©chantillonnage qui **sÃ©lectionne des exemples nÃ©gatifs difficiles** au lieu de nÃ©gatifs alÃ©atoires pendant l'entraÃ®nement.

### ProblÃ¨me avec Ã©chantillonnage alÃ©atoire

**Exemple concret** (votre dataset Crunchbase):
```
Positif: Google â†’ Sequoia Capital (vraie connexion)
NÃ©gatifs alÃ©atoires:
  - Google â†’ Random Small Fund #1 (facile - trÃ¨s diffÃ©rent)
  - Google â†’ Random Small Fund #2 (facile - trÃ¨s diffÃ©rent)
  - Google â†’ Random Small Fund #3 (facile - trÃ¨s diffÃ©rent)
```

Le modÃ¨le apprend Ã  distinguer des cas **Ã©vidents** mais pas les cas **subtils** qui comptent vraiment en Ã©valuation.

### Solution avec Hard Negative Mining

```
Positif: Google â†’ Sequoia Capital (vraie connexion)
NÃ©gatifs difficiles:
  - Google â†’ Andreessen Horowitz (difficile - profil similaire Ã  Sequoia)
  - Google â†’ Accel Partners (difficile - aussi top-tier VC)
  - Google â†’ Random Small Fund (facile - pour Ã©quilibre)
```

Le modÃ¨le est **forcÃ©** d'apprendre des distinctions fines entre investisseurs similaires.

## ğŸ¯ Pourquoi c'est crucial pour votre cas?

### RÃ©sultats actuels (Focal Loss seul)
- Precision@1000: 0.3% (3 vrais liens sur 1000 prÃ©dictions)
- Median rank: 5,623 / 170,742 (top 3.3%)
- **ProblÃ¨me**: Le modÃ¨le confond les vrais liens avec des faux liens similaires

### Attendu avec Hard Negative Mining
- Precision@1000: **1-2%** (10-20 vrais liens) - amÃ©lioration 3-7x
- Median rank: **<2,000** (top 1%)
- Le modÃ¨le apprend Ã  distinguer les vrais liens des "faux sosies"

## ğŸš€ Comment utiliser

### Option 1: Focal Loss + Hard Negatives (RECOMMANDÃ‰)

Combiner les deux techniques pour un effet maximal:

```bash
python train_self_supervised.py \
  --data crunchbase \
  --use_memory \
  --use_focal_loss \
  --focal_alpha 0.25 \
  --focal_gamma 2.0 \
  --use_hard_negatives \
  --hard_neg_ratio 0.5 \
  --hard_neg_temperature 0.1 \
  --prefix tgn-focal-hardneg \
  --n_epoch 50
```

### Option 2: Hard Negatives seul (sans Focal Loss)

```bash
python train_self_supervised.py \
  --data crunchbase \
  --use_memory \
  --use_hard_negatives \
  --hard_neg_ratio 0.5 \
  --hard_neg_temperature 0.1 \
  --prefix tgn-hardneg \
  --n_epoch 50
```

### Option 3: Baseline (Random sampling + BCE)

```bash
python train_self_supervised.py \
  --data crunchbase \
  --use_memory \
  --prefix tgn-baseline \
  --n_epoch 50
```

## âš™ï¸ HyperparamÃ¨tres

### `--hard_neg_ratio` (dÃ©faut: 0.5)

Proportion de nÃ©gatifs difficiles vs. alÃ©atoires:

```bash
--hard_neg_ratio 0.0    # 100% random (baseline)
--hard_neg_ratio 0.3    # 30% hard, 70% random (conservateur)
--hard_neg_ratio 0.5    # 50% hard, 50% random (RECOMMANDÃ‰)
--hard_neg_ratio 0.7    # 70% hard, 30% random (agressif)
--hard_neg_ratio 1.0    # 100% hard (trÃ¨s agressif)
```

**Recommandation**: Commencer Ã  0.5, puis expÃ©rimenter avec 0.7 si les rÃ©sultats sont bons.

### `--hard_neg_temperature` (dÃ©faut: 0.1)

ContrÃ´le l'agressivitÃ© du sampling:

```bash
--hard_neg_temperature 1.0    # Peu agressif (similaritÃ© moins importante)
--hard_neg_temperature 0.5    # ModÃ©rÃ©
--hard_neg_temperature 0.1    # Agressif (RECOMMANDÃ‰ - sÃ©lectionne les plus similaires)
--hard_neg_temperature 0.01   # TrÃ¨s agressif (seulement top similaires)
```

**Plus bas = plus agressif** = sÃ©lectionne les nÃ©gatifs les plus similaires au positif.

## ğŸ“Š Configurations recommandÃ©es

### Configuration 1: DÃ©marrage prudent
```bash
--use_hard_negatives \
--hard_neg_ratio 0.3 \
--hard_neg_temperature 0.1
```
â†³ 30% hard negatives, bon pour commencer

### Configuration 2: Ã‰quilibrÃ©e (RECOMMANDÃ‰E)
```bash
--use_hard_negatives \
--hard_neg_ratio 0.5 \
--hard_neg_temperature 0.1
```
â†³ 50-50 hard/random, meilleur Ã©quilibre

### Configuration 3: Agressive
```bash
--use_hard_negatives \
--hard_neg_ratio 0.7 \
--hard_neg_temperature 0.05
```
â†³ 70% hard negatives trÃ¨s similaires, pour maximiser la performance

### Configuration 4: Focal Loss + Hard Negatives
```bash
--use_focal_loss \
--focal_alpha 0.25 \
--focal_gamma 2.0 \
--use_hard_negatives \
--hard_neg_ratio 0.5 \
--hard_neg_temperature 0.1
```
â†³ Combine les deux techniques

## ğŸ§ª Tester Hard Negative Mining

VÃ©rifier que l'implÃ©mentation fonctionne:

```bash
python hard_negative_mining.py
```

Ce script affiche:
- Exemples de nÃ©gatifs Ã©chantillonnÃ©s
- Comparaison hard vs random sampling
- VÃ©rification que les hard negatives sont bien plus similaires

## ğŸ“ˆ Comparer les approches

### ExpÃ©rience complÃ¨te

EntraÃ®ner 4 modÃ¨les pour comparer:

```bash
# 1. Baseline (random + BCE)
python train_self_supervised.py \
  --data crunchbase --use_memory \
  --prefix baseline --n_epoch 50

# 2. Focal Loss seul
python train_self_supervised.py \
  --data crunchbase --use_memory \
  --use_focal_loss --focal_alpha 0.25 --focal_gamma 2.0 \
  --prefix focal --n_epoch 50

# 3. Hard Negatives seul
python train_self_supervised.py \
  --data crunchbase --use_memory \
  --use_hard_negatives --hard_neg_ratio 0.5 --hard_neg_temperature 0.1 \
  --prefix hardneg --n_epoch 50

# 4. Focal Loss + Hard Negatives
python train_self_supervised.py \
  --data crunchbase --use_memory \
  --use_focal_loss --focal_alpha 0.25 --focal_gamma 2.0 \
  --use_hard_negatives --hard_neg_ratio 0.5 --hard_neg_temperature 0.1 \
  --prefix focal-hardneg --n_epoch 50
```

### Ã‰valuer tous les modÃ¨les

```bash
# Baseline
python temporal_validation_diagnostic.py \
  --data crunchbase \
  --model_path saved_models/baseline-crunchbase.pth \
  --use_memory --auto_detect_params

# Focal
python temporal_validation_diagnostic.py \
  --data crunchbase \
  --model_path saved_models/focal-crunchbase.pth \
  --use_memory --auto_detect_params

# Hard Negatives
python temporal_validation_diagnostic.py \
  --data crunchbase \
  --model_path saved_models/hardneg-crunchbase.pth \
  --use_memory --auto_detect_params

# Focal + Hard Negatives
python temporal_validation_diagnostic.py \
  --data crunchbase \
  --model_path saved_models/focal-hardneg-crunchbase.pth \
  --use_memory --auto_detect_params
```

### MÃ©triques Ã  comparer

| MÃ©trique | Baseline | Focal | Hard Neg | Focal+Hard |
|----------|----------|-------|----------|------------|
| Precision@1000 | 0.3% | 0.3% | ? | ? |
| Recall@1000 | 5.8% | 5.8% | ? | ? |
| Median Rank | 6,609 | 5,623 | ? | ? |
| vs Random | 13x | 9.8x | ? | ? |

**HypothÃ¨se**: Focal+Hard devrait atteindre **Precision@1000 > 1%** et **Median Rank < 2,000**.

## ğŸ” Comment Ã§a marche?

### Algorithme

Pour chaque edge positif `(company, investor)`:

1. **Identifier les candidats nÃ©gatifs**: Tous les investisseurs NON connectÃ©s Ã  cette company
2. **Calculer similaritÃ©**: SimilaritÃ© cosinus entre `investor` et chaque candidat
3. **Ã‰chantillonner**:
   - `ratio * N` nÃ©gatifs parmi les plus similaires (hard)
   - `(1-ratio) * N` nÃ©gatifs alÃ©atoires (random)
4. **Retourner** le mÃ©lange de hard + random negatives

### SimilaritÃ© basÃ©e sur quoi?

**Node features bruts** (pas les embeddings temporels):
- Pour les companies: secteur, taille, annÃ©e de fondation, etc.
- Pour les investors: type (VC, angel), montant investi, stage prÃ©fÃ©rÃ©, etc.

**Avantage**: Rapide, pas besoin de recalculer Ã  chaque batch
**InconvÃ©nient**: Ne capture pas la dynamique temporelle (mais c'est OK)

## âš ï¸ Points d'attention

### 1. Temps d'entraÃ®nement

Hard Negative Mining est **~10-20% plus lent** que random sampling:
- Calcul de similaritÃ©: O(NÂ²) au pire cas
- OptimisÃ© avec des seuils (top-K uniquement)

**Exemple**:
- Random sampling: ~2 minutes/epoch
- Hard negative mining: ~2.5 minutes/epoch

### 2. Convergence

Peut nÃ©cessiter **plus d'epochs** pour converger:
- Les exemples sont plus difficiles
- Le modÃ¨le apprend plus lentement mais mieux

**Recommandation**: EntraÃ®ner pendant 50-100 epochs au lieu de 50.

### 3. Overfitting

Avec hard negatives, risque d'**overfitting** si:
- Dataset trÃ¨s petit
- `hard_neg_ratio` trop Ã©levÃ© (>0.8)

**Solution**:
- Surveiller val_ap vs train_loss
- Utiliser early stopping (dÃ©jÃ  implÃ©mentÃ©)

## ğŸ“ Fichiers modifiÃ©s

### 1. **hard_negative_mining.py** (NOUVEAU)
- `HardNegativeSampler`: Classe principale
- `BatchedHardNegativeSampler`: Version optimisÃ©e
- `build_adjacency_dict`: Utilitaire
- Tests unitaires

### 2. **train_self_supervised.py** (MODIFIÃ‰)
- Ligne 21: Import de `HardNegativeSampler`
- Lignes 92-97: Arguments CLI pour hard negative mining
- Lignes 160-167: Initialisation du sampler
- Lignes 330-343: Utilisation conditionnelle (hard vs random)
- Lignes 206-209: Logging wandb

## ğŸ”„ Comment revenir en arriÃ¨re?

Si Hard Negative Mining ne donne pas de bons rÃ©sultats:

**Ne PAS utiliser** le flag `--use_hard_negatives`:

```bash
# Revenir Ã  random sampling
python train_self_supervised.py \
  --data crunchbase --use_memory \
  --prefix fallback --n_epoch 50
```

Le code utilise automatiquement random sampling par dÃ©faut (ligne 342).

## ğŸ“ ThÃ©orie: Pourquoi Ã§a marche?

### Intuition

EntraÃ®nement = apprendre une **frontiÃ¨re de dÃ©cision** entre positifs et nÃ©gatifs.

**Random negatives**: FrontiÃ¨re facile
```
Positifs:     â—â—â—
NÃ©gatifs:                 â—‹â—‹â—‹
              ^^^^^^^^^^^
           FrontiÃ¨re large
```

**Hard negatives**: FrontiÃ¨re fine
```
Positifs:     â—â—â—
Hard Negs:      â—‹â—‹â—‹
              ^^^
        FrontiÃ¨re prÃ©cise
```

En forÃ§ant le modÃ¨le Ã  distinguer des cas similaires, on apprend une frontiÃ¨re **plus prÃ©cise**.

### Lien avec votre problÃ¨me

**Temporal Validation**: PrÃ©dire quels nouveaux investisseurs vont investir dans une company.

**DifficultÃ©**: Beaucoup d'investisseurs similaires (mÃªme profil, mÃªme stage, mÃªme secteur).

**Solution**: Hard Negative Mining force le modÃ¨le Ã  apprendre ce qui distingue *vraiment* un bon match d'un faux sosie.

## ğŸ“š RÃ©fÃ©rences

### Hard Negative Mining
- Schroff et al. (2015). "FaceNet: A Unified Embedding for Face Recognition and Clustering."
- Smirnov & Laptev (2001). "Hard Example Mining"

### Application aux graphes
- Abu-El-Haija et al. (2018). "Watch Your Step: Learning Node Embeddings via Graph Attention"
- Zhang & Chen (2018). "Link Prediction Based on Graph Neural Networks"

## ğŸ’¡ Prochaines Ã©tapes

Si Hard Negative Mining + Focal Loss ne suffisent pas:

1. **Temporal Hard Negatives**: Utiliser les embeddings temporels au lieu des features brutes
2. **Multi-hop Negatives**: Ã‰chantillonner des nÃ©gatifs Ã  distance 2-3 dans le graphe
3. **Curriculum Learning**: Augmenter progressivement `hard_neg_ratio` pendant l'entraÃ®nement
4. **Ensemble Methods**: Combiner plusieurs modÃ¨les entraÃ®nÃ©s diffÃ©remment

## âœ… Checklist d'utilisation

- [ ] Lancer le test: `python hard_negative_mining.py`
- [ ] EntraÃ®ner modÃ¨le baseline (sans hard negatives)
- [ ] EntraÃ®ner modÃ¨le avec hard negatives (ratio=0.5)
- [ ] Comparer les deux avec `temporal_validation_diagnostic.py`
- [ ] Si amÃ©lioration: expÃ©rimenter avec ratio=0.7
- [ ] Si pas d'amÃ©lioration: essayer tempÃ©rature plus Ã©levÃ©e (0.5)
- [ ] Documenter les meilleurs hyperparamÃ¨tres trouvÃ©s
