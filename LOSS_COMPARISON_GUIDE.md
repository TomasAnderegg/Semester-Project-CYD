# Guide: Comparaison des Loss Functions

Ce guide explique comment entra√Æner ton mod√®le TGN avec diff√©rentes loss functions et comparer leurs performances.

## 1. Entra√Æner avec Diff√©rentes Loss Functions

### BCE Loss (Baseline)
```bash
python train_self_supervised.py --data crunchbase --prefix tgn-attn --use_memory
```
R√©sultats sauvegard√©s: `results/tgn-attn_bce.json`

### Focal Loss
```bash
python train_self_supervised.py --data crunchbase --prefix tgn-attn --use_memory \
  --use_focal_loss --focal_alpha 0.25 --focal_gamma 2.0
```
R√©sultats sauvegard√©s: `results/tgn-attn_focal.json`

### HAR Loss (Hardness Adaptive Reweighted)
```bash
python train_self_supervised.py --data crunchbase --prefix tgn-attn --use_memory \
  --use_har_loss --har_alpha 0.5 --har_temperature 0.07
```
R√©sultats sauvegard√©s: `results/tgn-attn_har.json`

### Hybrid Loss (Focal + HAR)
```bash
python train_self_supervised.py --data crunchbase --prefix tgn-attn --use_memory \
  --use_focal_loss --focal_alpha 0.25 --focal_gamma 2.0 \
  --use_har_loss --har_alpha 0.5 --har_temperature 0.07
```
R√©sultats sauvegard√©s: `results/tgn-attn_hybrid.json`

## 2. Comparer les R√©sultats

Une fois que tu as entra√Æn√© plusieurs mod√®les, lance le script de comparaison:

```bash
python plot_loss_comparison.py
```

## 3. Outputs G√©n√©r√©s

Le script g√©n√®re automatiquement dans `loss_comparison_plots/`:

### üìä `training_loss_comparison.png`
- Courbes de training loss par epoch
- Compare BCE vs Focal vs HAR vs Hybrid
- Permet de voir quelle loss converge le mieux

### üìä `test_metrics_comparison.png`
- Bar charts des m√©triques finales de test
- AUROC, AP, MRR, Recall@10, Recall@50
- Comparaison directe des performances

### üìä `validation_metrics_over_epochs.png`
- √âvolution des m√©triques de validation
- 4 subplots: MRR, AP, Recall@10, Recall@50
- Montre la stabilit√© de l'entra√Ænement

### üìÑ `summary_table.csv`
- Tableau r√©capitulatif de toutes les m√©triques
- Inclut les hyperparam√®tres utilis√©s
- Format CSV facile √† importer dans Excel

## 4. Structure des Fichiers de R√©sultats

Chaque entra√Ænement g√©n√®re 2 fichiers:

### `results/{prefix}_{loss}.pkl` (Pickle)
Format binaire Python contenant toutes les donn√©es brutes.

### `results/{prefix}_{loss}.json` (JSON)
Format lisible contenant:
```json
{
  "loss_function": "har",
  "config": {
    "focal_alpha": null,
    "focal_gamma": null,
    "har_alpha": 0.5,
    "har_temperature": 0.07
  },
  "validation": {
    "ap": [0.782, 0.795, ...],
    "mrr": [0.306, 0.315, ...],
    "recall_10": [0.382, 0.391, ...],
    "recall_50": [0.852, 0.861, ...]
  },
  "test": {
    "ap": 0.807,
    "auc": 0.767,
    "mrr": 0.531,
    "recall_10": 0.611,
    "recall_50": 0.788
  },
  "training": {
    "losses": [0.642, 0.589, 0.521, ...],
    "epoch_times": [45.2, 44.8, 45.1, ...]
  }
}
```

## 5. Interpr√©tation des R√©sultats

### Training Loss
- **Plus bas = meilleur** (convergence)
- V√©rifie qu'il n'y a pas d'overfitting (√©cart train/val)

### AUROC & AP
- **Classification metrics**
- Plus haut = meilleure discrimination positif/n√©gatif
- Optimal: > 0.75

### MRR (Mean Reciprocal Rank)
- **Ranking metric**
- Plus haut = meilleur classement du vrai investisseur
- Optimal: > 0.5

### Recall@K
- **Ranking metric**
- Recall@10: % de vrais investisseurs dans top-10
- Recall@50: % de vrais investisseurs dans top-50
- Optimal: > 0.60 pour @10, > 0.80 pour @50

## 6. Recommandations

### Pour le Degree Bias
Si ton dataset a un **fort d√©s√©quilibre de degr√©s** (quelques n≈ìuds tr√®s connect√©s):
- ‚úÖ Utilise **HAR Loss** ou **Hybrid Loss**
- üìä Compare avec BCE pour quantifier l'am√©lioration

### Pour le Class Imbalance
Si tu as **beaucoup plus de n√©gatifs que de positifs**:
- ‚úÖ Utilise **Focal Loss** ou **Hybrid Loss**
- ‚öôÔ∏è Tune `focal_gamma` (2.0-5.0) pour ajuster l'agressivit√©

### Pour les Deux Probl√®mes
Si tu as **degree bias ET class imbalance**:
- ‚úÖ Utilise **Hybrid Loss**
- ‚öôÔ∏è Ajuste `lambda_focal` dans hybrid_loss.py (0.5 = √©quilibr√©)

## 7. Troubleshooting

### Probl√®me: "Aucun fichier de r√©sultats trouv√©"
**Solution**: Entra√Æne d'abord au moins un mod√®le (voir section 1)

### Probl√®me: Training loss n'appara√Æt pas sur le plot
**Solution**: V√©rifie que l'entra√Ænement s'est termin√© compl√®tement (pas d'interruption)

### Probl√®me: M√©triques de test manquantes
**Solution**: Assure-toi que l'√©valuation de test s'est bien ex√©cut√©e apr√®s l'entra√Ænement

### Probl√®me: Courbes trop bruit√©es
**Solution**: Augmente `--n_epoch` pour avoir plus de donn√©es

## 8. Exemple Complet

```bash
# 1. Entra√Æner les 4 configurations
python train_self_supervised.py --data crunchbase --prefix tgn-attn --use_memory --n_epoch 50
python train_self_supervised.py --data crunchbase --prefix tgn-attn --use_memory --n_epoch 50 --use_focal_loss
python train_self_supervised.py --data crunchbase --prefix tgn-attn --use_memory --n_epoch 50 --use_har_loss
python train_self_supervised.py --data crunchbase --prefix tgn-attn --use_memory --n_epoch 50 --use_focal_loss --use_har_loss

# 2. Comparer les r√©sultats
python plot_loss_comparison.py

# 3. Visualiser les plots
# Les fichiers sont dans loss_comparison_plots/
```

## 9. R√©f√©rences

- **BCE Loss**: Binary Cross-Entropy (baseline PyTorch)
- **Focal Loss**: Lin et al., "Focal Loss for Dense Object Detection" (2017)
- **HAR Loss**: Adapt√©e de "Graph Contrastive Learning with Adaptive Augmentation" (2021)
- **Hybrid Loss**: Combinaison custom Focal + HAR
