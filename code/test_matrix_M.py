import pandas as pd
import pickle
import os
import networkx as nx
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from pathlib import Path
from scipy.stats import powerlaw
import warnings
warnings.filterwarnings('ignore')

# ===================================================================
# CONFIGURATION
# ===================================================================

NUM_COMP = 500
NUM_TECH = 500
FLAG_CYBERSECURITY = True

SAVE_DIR_CLASSES = "savings/bipartite_tech_comp/classes"
SAVE_DIR_NETWORKS = "savings/bipartite_tech_comp/networks"
SAVE_DIR_M = "savings/bipartite_tech_comp/M"
SAVE_DIR_ANALYSIS = "analysis/graph_quality"

# ===================================================================
# CHARGEMENT DES DONN√âES
# ===================================================================

def load_graph_and_matrix(num_comp, num_tech, flag_cybersecurity):
    """Charge le graphe et la matrice d'adjacence"""
    prefix = "cybersecurity_" if flag_cybersecurity else ""
    
    # Charger le graphe
    graph_path = f'{SAVE_DIR_NETWORKS}/{prefix}bipartite_graph_{num_comp}.gpickle'
    with open(graph_path, 'rb') as f:
        B = pickle.load(f)
    
    # Charger la matrice
    matrix_path = f'{SAVE_DIR_M}/{prefix}comp_{num_comp}_tech_{num_tech}.npy'
    M = np.load(matrix_path)
    
    # Charger les dictionnaires
    with open(f'{SAVE_DIR_CLASSES}/{prefix}dict_companies_ranked_{num_comp}.pickle', 'rb') as f:
        dict_companies = pickle.load(f)
    
    with open(f'{SAVE_DIR_CLASSES}/{prefix}dict_tech_ranked_{num_tech}.pickle', 'rb') as f:
        dict_tech = pickle.load(f)
    
    print(f"‚úì Donn√©es charg√©es:")
    print(f"  - Graphe: {B.number_of_nodes()} n≈ìuds, {B.number_of_edges()} ar√™tes")
    print(f"  - Matrice: {M.shape}")
    print(f"  - Dictionnaires: {len(dict_companies)} companies, {len(dict_tech)} technologies")
    
    return B, M, dict_companies, dict_tech


# ===================================================================
# ANALYSES STRUCTURELLES DU GRAPHE
# ===================================================================

def analyze_graph_structure(B):
    """Analyse d√©taill√©e de la structure du graphe bipartite"""
    print("\n" + "="*70)
    print("ANALYSE STRUCTURELLE DU GRAPHE")
    print("="*70)
    
    companies = [n for n, d in B.nodes(data=True) if d.get('bipartite') == 0]
    techs = [n for n, d in B.nodes(data=True) if d.get('bipartite') == 1]
    
    print(f"\nüìä COMPOSITION:")
    print(f"  - Companies: {len(companies)}")
    print(f"  - Technologies: {len(techs)}")
    print(f"  - Ar√™tes: {B.number_of_edges()}")
    print(f"  - Densit√©: {nx.density(B):.4f}")
    
    # Degr√©s
    company_degrees = [B.degree(node) for node in companies]
    tech_degrees = [B.degree(node) for node in techs]
    
    print(f"\nüìà DEGR√âS:")
    print(f"  Companies:")
    print(f"    - Moyen: {np.mean(company_degrees):.2f}")
    print(f"    - M√©dian: {np.median(company_degrees):.2f}")
    print(f"    - Min/Max: {np.min(company_degrees)}/{np.max(company_degrees)}")
    print(f"    - √âcart-type: {np.std(company_degrees):.2f}")
    
    print(f"  Technologies:")
    print(f"    - Moyen: {np.mean(tech_degrees):.2f}")
    print(f"    - M√©dian: {np.median(tech_degrees):.2f}")
    print(f"    - Min/Max: {np.min(tech_degrees)}/{np.max(tech_degrees)}")
    print(f"    - √âcart-type: {np.std(tech_degrees):.2f}")
    
    # N≈ìuds isol√©s
    isolated = list(nx.isolates(B))
    print(f"\n‚ö†Ô∏è  N≈íUDS ISOL√âS: {len(isolated)}")
    if isolated:
        print(f"  Exemples: {isolated[:5]}")
    
    # Composantes connexes
    components = list(nx.connected_components(B))
    print(f"\nüîó COMPOSANTES CONNEXES: {len(components)}")
    
    if len(components) > 1:
        comp_sizes = sorted([len(c) for c in components], reverse=True)
        print(f"  Tailles: {comp_sizes[:10]}")
        largest = max(components, key=len)
        print(f"  Plus grande composante: {len(largest)} n≈ìuds ({len(largest)/B.number_of_nodes()*100:.1f}%)")
    
    return {
        'companies': companies,
        'techs': techs,
        'company_degrees': company_degrees,
        'tech_degrees': tech_degrees,
        'components': components
    }


def analyze_matrix_properties(M):
    """Analyse d√©taill√©e de la matrice d'adjacence"""
    print("\n" + "="*70)
    print("ANALYSE DE LA MATRICE D'ADJACENCE")
    print("="*70)
    
    print(f"\nüìê DIMENSIONS:")
    print(f"  - Shape: {M.shape}")
    print(f"  - Companies (lignes): {M.shape[0]}")
    print(f"  - Technologies (colonnes): {M.shape[1]}")
    
    print(f"\nüî¢ STATISTIQUES:")
    print(f"  - Somme totale: {np.sum(M):.0f}")
    print(f"  - Densit√©: {np.sum(M) / (M.shape[0] * M.shape[1]):.4f}")
    print(f"  - Valeurs uniques: {np.unique(M)}")
    
    # Distribution des connexions
    row_sums = np.sum(M, axis=1)
    col_sums = np.sum(M, axis=0)
    
    print(f"\nüìä DISTRIBUTION DES CONNEXIONS:")
    print(f"  Par company (lignes):")
    print(f"    - Moyenne: {np.mean(row_sums):.2f}")
    print(f"    - M√©diane: {np.median(row_sums):.2f}")
    print(f"    - Min/Max: {np.min(row_sums):.0f}/{np.max(row_sums):.0f}")
    print(f"    - Companies sans connexion: {np.sum(row_sums == 0)}")
    
    print(f"  Par technologie (colonnes):")
    print(f"    - Moyenne: {np.mean(col_sums):.2f}")
    print(f"    - M√©diane: {np.median(col_sums):.2f}")
    print(f"    - Min/Max: {np.min(col_sums):.0f}/{np.max(col_sums):.0f}")
    print(f"    - Technologies sans connexion: {np.sum(col_sums == 0)}")
    
    # V√©rifications de coh√©rence
    print(f"\n‚úÖ V√âRIFICATIONS:")
    print(f"  - Matrice binaire: {np.all((M == 0) | (M == 1))}")
    print(f"  - Pas de NaN: {not np.any(np.isnan(M))}")
    print(f"  - Pas d'infini: {not np.any(np.isinf(M))}")
    
    return {
        'row_sums': row_sums,
        'col_sums': col_sums
    }


def check_matrix_graph_consistency(B, M):
    """V√©rifie la coh√©rence entre le graphe et la matrice"""
    print("\n" + "="*70)
    print("V√âRIFICATION COH√âRENCE GRAPHE ‚Üî MATRICE")
    print("="*70)
    
    companies = [n for n, d in B.nodes(data=True) if d.get('bipartite') == 0]
    techs = [n for n, d in B.nodes(data=True) if d.get('bipartite') == 1]
    
    # Comparer les dimensions
    print(f"\nüìè DIMENSIONS:")
    print(f"  Graphe: {len(companies)} companies √ó {len(techs)} technologies")
    print(f"  Matrice: {M.shape[0]} √ó {M.shape[1]}")
    
    dim_match = (len(companies) == M.shape[0]) and (len(techs) == M.shape[1])
    print(f"  ‚úì Dimensions coh√©rentes: {dim_match}")
    
    # Comparer le nombre d'ar√™tes
    edges_graph = B.number_of_edges()
    edges_matrix = int(np.sum(M))
    
    print(f"\nüîó AR√äTES:")
    print(f"  Graphe: {edges_graph}")
    print(f"  Matrice: {edges_matrix}")
    print(f"  Diff√©rence: {abs(edges_graph - edges_matrix)}")
    
    edges_match = (edges_graph == edges_matrix)
    print(f"  ‚úì Nombre d'ar√™tes coh√©rent: {edges_match}")
    
    if edges_match and dim_match:
        print(f"\n‚úÖ GRAPHE ET MATRICE SONT COH√âRENTS")
    else:
        print(f"\n‚ö†Ô∏è  INCOH√âRENCE D√âTECT√âE!")
    
    return dim_match and edges_match


# ===================================================================
# VISUALISATIONS
# ===================================================================

def plot_degree_distributions(graph_data, matrix_data):
    """Visualise les distributions de degr√©s"""
    fig, axes = plt.subplots(2, 2, figsize=(15, 12))
    
    # Distribution des degr√©s - Companies
    axes[0, 0].hist(graph_data['company_degrees'], bins=30, edgecolor='black', alpha=0.7, color='red')
    axes[0, 0].set_xlabel('Degr√©')
    axes[0, 0].set_ylabel('Fr√©quence')
    axes[0, 0].set_title('Distribution des degr√©s - Companies')
    axes[0, 0].axvline(np.mean(graph_data['company_degrees']), color='black', 
                       linestyle='--', label=f'Moyenne: {np.mean(graph_data["company_degrees"]):.2f}')
    axes[0, 0].legend()
    axes[0, 0].grid(True, alpha=0.3)
    
    # Distribution des degr√©s - Technologies
    axes[0, 1].hist(graph_data['tech_degrees'], bins=30, edgecolor='black', alpha=0.7, color='blue')
    axes[0, 1].set_xlabel('Degr√©')
    axes[0, 1].set_ylabel('Fr√©quence')
    axes[0, 1].set_title('Distribution des degr√©s - Technologies')
    axes[0, 1].axvline(np.mean(graph_data['tech_degrees']), color='black', 
                       linestyle='--', label=f'Moyenne: {np.mean(graph_data["tech_degrees"]):.2f}')
    axes[0, 1].legend()
    axes[0, 1].grid(True, alpha=0.3)
    
    # Log-log plot - Companies
    hist, bins = np.histogram(graph_data['company_degrees'], bins=50)
    bin_centers = (bins[:-1] + bins[1:]) / 2
    axes[1, 0].loglog(bin_centers, hist, 'ro-', alpha=0.6)
    axes[1, 0].set_xlabel('Degr√© (log)')
    axes[1, 0].set_ylabel('Fr√©quence (log)')
    axes[1, 0].set_title('Distribution log-log - Companies')
    axes[1, 0].grid(True, alpha=0.3)
    
    # Log-log plot - Technologies
    hist, bins = np.histogram(graph_data['tech_degrees'], bins=50)
    bin_centers = (bins[:-1] + bins[1:]) / 2
    axes[1, 1].loglog(bin_centers, hist, 'bo-', alpha=0.6)
    axes[1, 1].set_xlabel('Degr√© (log)')
    axes[1, 1].set_ylabel('Fr√©quence (log)')
    axes[1, 1].set_title('Distribution log-log - Technologies')
    axes[1, 1].grid(True, alpha=0.3)
    
    plt.tight_layout()
    plt.savefig(f'{SAVE_DIR_ANALYSIS}/degree_distributions.png', dpi=300, bbox_inches='tight')
    print(f"‚úì Graphique sauvegard√©: {SAVE_DIR_ANALYSIS}/degree_distributions.png")
    plt.show()


def plot_matrix_visualization(M):
    """Visualise la matrice d'adjacence tri√©e"""
    fig, axes = plt.subplots(1, 2, figsize=(16, 7))
    
    # Matrice brute
    axes[0].imshow(M, cmap='bone', interpolation='nearest', aspect='auto')
    axes[0].set_xlabel('Technologies')
    axes[0].set_ylabel('Companies')
    axes[0].set_title('Matrice d\'adjacence (brute)')
    
    # Matrice tri√©e (triangularit√©)
    row_sums = np.sum(M, axis=1)
    col_sums = np.sum(M, axis=0)
    
    row_order = np.argsort(row_sums)
    col_order = np.argsort(col_sums)
    
    M_sorted = M[row_order, :][:, col_order]
    
    axes[1].imshow(M_sorted, cmap='bone', interpolation='nearest', aspect='auto')
    axes[1].set_xlabel('Technologies (tri√©es)')
    axes[1].set_ylabel('Companies (tri√©es)')
    axes[1].set_title('Matrice d\'adjacence (tri√©e par degr√©)')
    
    plt.tight_layout()
    plt.savefig(f'{SAVE_DIR_ANALYSIS}/matrix_visualization.png', dpi=300, bbox_inches='tight')
    print(f"‚úì Graphique sauvegard√©: {SAVE_DIR_ANALYSIS}/matrix_visualization.png")
    plt.show()


def plot_connectivity_heatmap(matrix_data):
    """Heatmap de la connectivit√©"""
    fig, axes = plt.subplots(1, 2, figsize=(15, 5))
    
    # Distribution des connexions par company
    row_sums = matrix_data['row_sums']
    bins_comp = np.linspace(0, np.max(row_sums), 20)
    axes[0].hist(row_sums, bins=bins_comp, edgecolor='black', alpha=0.7, color='red')
    axes[0].set_xlabel('Nombre de technologies')
    axes[0].set_ylabel('Nombre de companies')
    axes[0].set_title('Connexions par company')
    axes[0].axvline(np.mean(row_sums), color='black', linestyle='--', 
                    label=f'Moyenne: {np.mean(row_sums):.2f}')
    axes[0].legend()
    axes[0].grid(True, alpha=0.3)
    
    # Distribution des connexions par technologie
    col_sums = matrix_data['col_sums']
    bins_tech = np.linspace(0, np.max(col_sums), 20)
    axes[1].hist(col_sums, bins=bins_tech, edgecolor='black', alpha=0.7, color='blue')
    axes[1].set_xlabel('Nombre de companies')
    axes[1].set_ylabel('Nombre de technologies')
    axes[1].set_title('Connexions par technologie')
    axes[1].axvline(np.mean(col_sums), color='black', linestyle='--', 
                    label=f'Moyenne: {np.mean(col_sums):.2f}')
    axes[1].legend()
    axes[1].grid(True, alpha=0.3)
    
    plt.tight_layout()
    plt.savefig(f'{SAVE_DIR_ANALYSIS}/connectivity_heatmap.png', dpi=300, bbox_inches='tight')
    print(f"‚úì Graphique sauvegard√©: {SAVE_DIR_ANALYSIS}/connectivity_heatmap.png")
    plt.show()


# ===================================================================
# ANALYSE POUR TECHRANK
# ===================================================================

def assess_techrank_readiness(B, M, graph_data, matrix_data):
    """√âvalue si le graphe est pr√™t pour TechRank"""
    print("\n" + "="*70)
    print("√âVALUATION DE LA PR√âPARATION POUR TECHRANK")
    print("="*70)
    
    issues = []
    warnings_list = []
    
    # 1. V√©rifier les n≈ìuds isol√©s
    isolated = list(nx.isolates(B))
    if len(isolated) > 0:
        issues.append(f"‚ö†Ô∏è  {len(isolated)} n≈ìuds isol√©s d√©tect√©s")
    
    # 2. V√©rifier les companies sans connexion
    row_sums = matrix_data['row_sums']
    zero_degree_companies = np.sum(row_sums == 0)
    if zero_degree_companies > 0:
        issues.append(f"‚ö†Ô∏è  {zero_degree_companies} companies sans connexion")
    
    # 3. V√©rifier les technologies sans connexion
    col_sums = matrix_data['col_sums']
    zero_degree_techs = np.sum(col_sums == 0)
    if zero_degree_techs > 0:
        issues.append(f"‚ö†Ô∏è  {zero_degree_techs} technologies sans connexion")
    
    # 4. V√©rifier la composante connexe principale
    components = graph_data['components']
    if len(components) > 1:
        largest_comp_size = len(max(components, key=len))
        coverage = largest_comp_size / B.number_of_nodes() * 100
        if coverage < 90:
            warnings_list.append(f"‚ö†Ô∏è  Composante principale couvre seulement {coverage:.1f}% du graphe")
    
    # 5. V√©rifier la densit√©
    density = nx.density(B)
    if density < 0.001:
        warnings_list.append(f"‚ö†Ô∏è  Graphe tr√®s sparse (densit√©: {density:.6f})")
    
    # 6. V√©rifier la distribution des degr√©s
    company_degrees = graph_data['company_degrees']
    tech_degrees = graph_data['tech_degrees']
    
    if np.std(company_degrees) / np.mean(company_degrees) > 2:
        warnings_list.append(f"‚ö†Ô∏è  Forte h√©t√©rog√©n√©it√© des degr√©s companies (CV: {np.std(company_degrees) / np.mean(company_degrees):.2f})")
    
    if np.std(tech_degrees) / np.mean(tech_degrees) > 2:
        warnings_list.append(f"‚ö†Ô∏è  Forte h√©t√©rog√©n√©it√© des degr√©s technologies (CV: {np.std(tech_degrees) / np.mean(tech_degrees):.2f})")
    
    # Afficher les r√©sultats
    if not issues and not warnings_list:
        print("\n‚úÖ GRAPHE PR√äT POUR TECHRANK")
        print("  Aucun probl√®me critique d√©tect√©")
    else:
        if issues:
            print("\n‚ùå PROBL√àMES CRITIQUES:")
            for issue in issues:
                print(f"  {issue}")
        
        if warnings_list:
            print("\n‚ö†Ô∏è  AVERTISSEMENTS:")
            for warning in warnings_list:
                print(f"  {warning}")
    
    # Recommandations
    print("\nüí° RECOMMANDATIONS:")
    if zero_degree_companies > 0 or zero_degree_techs > 0:
        print("  1. Supprimer les n≈ìuds sans connexion avant d'appliquer TechRank")
    
    if len(components) > 1:
        print("  2. Consid√©rer d'analyser uniquement la composante connexe principale")
    
    if density < 0.001:
        print("  3. Le graphe sparse peut n√©cessiter plus d'it√©rations pour converger")
    
    return len(issues) == 0


# ===================================================================
# RAPPORT COMPLET
# ===================================================================

def generate_analysis_report(B, M, dict_companies, dict_tech):
    """G√©n√®re un rapport d'analyse complet"""
    Path(SAVE_DIR_ANALYSIS).mkdir(parents=True, exist_ok=True)
    
    print("\n" + "="*70)
    print("G√âN√âRATION DU RAPPORT D'ANALYSE")
    print("="*70)
    
    # 1. Analyse structurelle
    graph_data = analyze_graph_structure(B)
    
    # 2. Analyse de la matrice
    matrix_data = analyze_matrix_properties(M)
    
    # 3. V√©rification de coh√©rence
    is_consistent = check_matrix_graph_consistency(B, M)
    
    # 4. Visualisations
    print("\nüìä G√©n√©ration des visualisations...")
    plot_degree_distributions(graph_data, matrix_data)
    plot_matrix_visualization(M)
    plot_connectivity_heatmap(matrix_data)
    
    # 5. √âvaluation TechRank
    is_ready = assess_techrank_readiness(B, M, graph_data, matrix_data)
    
    # 6. Sauvegarder un r√©sum√© textuel
    summary_path = f'{SAVE_DIR_ANALYSIS}/analysis_summary.txt'
    with open(summary_path, 'w', encoding='utf-8') as f:
        f.write("="*70 + "\n")
        f.write("RAPPORT D'ANALYSE DU GRAPHE BIPARTITE\n")
        f.write("="*70 + "\n\n")
        
        f.write("COMPOSITION:\n")
        f.write(f"  - Companies: {len(graph_data['companies'])}\n")
        f.write(f"  - Technologies: {len(graph_data['techs'])}\n")
        f.write(f"  - Ar√™tes: {B.number_of_edges()}\n")
        f.write(f"  - Densit√©: {nx.density(B):.6f}\n\n")
        
        f.write("DEGR√âS MOYENS:\n")
        f.write(f"  - Companies: {np.mean(graph_data['company_degrees']):.2f}\n")
        f.write(f"  - Technologies: {np.mean(graph_data['tech_degrees']):.2f}\n\n")
        
        f.write("COH√âRENCE GRAPHE-MATRICE:\n")
        f.write(f"  - Coh√©rent: {'OUI' if is_consistent else 'NON'}\n\n")
        
        f.write("PR√äT POUR TECHRANK:\n")
        f.write(f"  - {'OUI' if is_ready else 'NON - voir avertissements ci-dessus'}\n")
    
    print(f"\n‚úì R√©sum√© sauvegard√©: {summary_path}")
    print(f"\n‚úÖ ANALYSE COMPL√àTE TERMIN√âE")
    print(f"   Tous les r√©sultats sont dans: {SAVE_DIR_ANALYSIS}/")


# ===================================================================
# MAIN
# ===================================================================

if __name__ == "__main__":
    # Charger les donn√©es
    B, M, dict_companies, dict_tech = load_graph_and_matrix(
        NUM_COMP, NUM_TECH, FLAG_CYBERSECURITY
    )
    
    # G√©n√©rer le rapport complet
    generate_analysis_report(B, M, dict_companies, dict_tech)