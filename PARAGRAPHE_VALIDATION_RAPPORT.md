# Paragraphes pour Rapport : Validation du Mod√®le

## Version 1 : Courte (1 paragraphe, ~150 mots)

### Pour section "M√©thodologie" ou "Exp√©rimentation"

Pour √©valuer notre mod√®le TGN, nous adoptons une approche de **validation temporelle** stricte, o√π les donn√©es sont divis√©es chronologiquement en ensembles d'entra√Ænement (70%), validation (15%) et test (15%). Cette strat√©gie garantit que le mod√®le pr√©dit uniquement des interactions futures, refl√©tant ainsi un sc√©nario d'utilisation r√©aliste. L'√©valuation se base sur des **m√©triques de ranking** plut√¥t que sur une simple classification binaire : pour chaque lien positif du test set, nous calculons son rang parmi un ensemble de candidats n√©gatifs √©chantillonn√©s al√©atoirement. Nous mesurons le **Mean Reciprocal Rank (MRR)**, qui quantifie la position moyenne du vrai lien dans le classement, ainsi que le **Recall@K**, repr√©sentant la proportion de vrais liens retrouv√©s dans les top-K pr√©dictions. Nous reportons √©galement l'**Average Precision (AP)** et l'**AUC-ROC** pour permettre la comparaison avec les approches de classification binaire traditionnelles. Cette m√©thodologie multi-m√©trique permet d'√©valuer √† la fois la capacit√© discriminative du mod√®le et sa pertinence pratique pour des syst√®mes de recommandation.

---

## Version 2 : Moyenne (2 paragraphes, ~250 mots)

### Pour section "M√©thodologie Exp√©rimentale"

**Validation Temporelle.** Afin de respecter la nature dynamique des graphes temporels et d'√©viter toute fuite d'information (*temporal leakage*), nous adoptons une strat√©gie de validation temporelle stricte. Les interactions sont divis√©es chronologiquement selon les quantiles temporels : les 70% premi√®res interactions constituent l'ensemble d'entra√Ænement, les 15% suivantes l'ensemble de validation pour le r√©glage des hyperparam√®tres, et les 15% finales l'ensemble de test pour l'√©valuation finale. Cette s√©paration garantit que le mod√®le ne pr√©dit jamais des √©v√©nements pass√©s, simulant ainsi un d√©ploiement r√©aliste o√π seules les informations historiques sont disponibles au moment de la pr√©diction.

**M√©triques d'√âvaluation.** Plut√¥t qu'une simple classification binaire, nous √©valuons le mod√®le selon une approche de **ranking**, plus repr√©sentative des applications pratiques en recommandation d'investisseurs. Pour chaque lien positif (u, v, t) du test set, nous calculons son score ainsi que les scores de N = 100 candidats n√©gatifs √©chantillonn√©s al√©atoirement. Le **Mean Reciprocal Rank (MRR)** mesure la position moyenne du vrai lien dans ce classement, tandis que le **Recall@K** quantifie la proportion de vrais liens pr√©sents dans les top-K pr√©dictions (nous reportons K ‚àà {10, 50, 1000}). Nous compl√©tons cette √©valuation par l'**Average Precision (AP)** et l'**AUC-ROC**, m√©triques standard pour la pr√©diction de liens, permettant ainsi une comparaison directe avec les travaux ant√©rieurs. L'ensemble de ces m√©triques offre une vue multidimensionnelle de la performance du mod√®le, √©valuant √† la fois sa pr√©cision discriminative et son utilit√© pour un syst√®me de recommandation en production.

---

## Version 3 : Longue (3-4 paragraphes, ~400 mots)

### Pour section "M√©thodologie" d√©taill√©e

**Protocole de Validation Temporelle.** La validation de mod√®les sur des graphes temporels n√©cessite une attention particuli√®re pour √©viter le *temporal leakage*, o√π des informations futures contamineraient l'apprentissage. Nous adoptons donc une strat√©gie de **division temporelle stricte** bas√©e sur les timestamps des interactions. Soit T l'ensemble des timestamps, nous d√©finissons t‚Çá‚ÇÄ et t‚Çà‚ÇÖ comme les 70√®me et 85√®me quantiles de T. Les interactions avec t < t‚Çá‚ÇÄ constituent l'ensemble d'entra√Ænement (70% des donn√©es), celles avec t‚Çá‚ÇÄ ‚â§ t < t‚Çà‚ÇÖ forment l'ensemble de validation (15%), et les interactions avec t ‚â• t‚Çà‚ÇÖ constituent l'ensemble de test (15%). Cette partition garantit que le mod√®le, entra√Æn√© sur le pass√©, est √©valu√© exclusivement sur sa capacit√© √† pr√©dire le futur, refl√©tant ainsi fid√®lement un sc√©nario de d√©ploiement r√©el.

**√âvaluation par Ranking.** Contrairement aux approches de classification binaire traditionnelles qui √©valuent la capacit√© du mod√®le √† distinguer un lien positif d'un n√©gatif arbitraire, nous adoptons une m√©thodologie de **ranking** plus repr√©sentative des applications pratiques. Pour chaque interaction test (u, v, t), nous g√©n√©rons un ensemble de N candidats comprenant le n≈ìud destination r√©el v et N - 1 n≈ìuds n√©gatifs √©chantillonn√©s uniform√©ment parmi tous les n≈ìuds possibles (excluant v). Le mod√®le calcule un score pour chaque candidat, et nous mesurons le rang r du n≈ìud positif v dans le classement d√©croissant de ces scores. Cette approche simule directement une t√¢che de recommandation o√π le syst√®me doit identifier le bon candidat parmi un large ensemble de possibilit√©s.

**M√©triques Utilis√©es.** Nous reportons quatre familles de m√©triques compl√©mentaires. Le **Mean Reciprocal Rank (MRR = 1/|Test| Œ£·µ¢ 1/r·µ¢)** quantifie la position moyenne des vrais liens dans le classement, avec des valeurs proches de 1 indiquant que les vrais liens sont syst√©matiquement bien class√©s. Le **Recall@K** mesure la proportion de vrais liens pr√©sents dans les top-K pr√©dictions : Recall@K = |{i : r·µ¢ ‚â§ K}| / |Test|. Nous reportons K ‚àà {10, 50, 1000} pour capturer diff√©rents r√©gimes de pr√©cision. L'**Average Precision (AP)**, d√©finie comme l'aire sous la courbe Precision-Recall, √©value la qualit√© globale du classement tout en √©tant robuste au d√©s√©quilibre de classes. Enfin, l'**AUC-ROC** mesure la capacit√© du mod√®le √† distinguer les classes positives et n√©gatives. Ces m√©triques, couramment utilis√©es dans la litt√©rature sur la pr√©diction de liens [Rossi et al., 2020; Kumar et al., 2020], permettent une comparaison directe avec les approches de l'√©tat de l'art.

**Baseline Al√©atoire.** Pour contextualiser nos r√©sultats, nous comparons syst√©matiquement avec une baseline al√©atoire. Dans notre dataset CrunchBase, avec 52 liens positifs sur 170,742 paires possibles (ratio 0.03%), un classement al√©atoire atteindrait un Recall@1000 de 0.6%. Tout mod√®le significativement au-dessus de ce seuil d√©montre une capacit√© d'apprentissage r√©elle. Nous mesurons l'am√©lioration relative comme le ratio entre le Recall@K du mod√®le et celui de la baseline al√©atoire, fournissant ainsi une interpr√©tation intuitive de la performance.

---

## Version 4 : Tr√®s Formelle (Style Article Scientifique, ~300 mots)

### Pour article de conf√©rence (NeurIPS, ICML, KDD, etc.)

**Experimental Protocol.** Following standard practices in temporal graph learning [Rossi et al., 2020; Kumar et al., 2020], we employ a strict temporal validation protocol to prevent information leakage. Let ‚Ñ∞ = {(u, v, t)} denote the set of all interactions. We partition ‚Ñ∞ into train, validation, and test sets based on temporal quantiles: ‚Ñ∞_train = {(u, v, t) : t < q‚ÇÄ.‚Çá‚ÇÄ}, ‚Ñ∞_val = {(u, v, t) : q‚ÇÄ.‚Çá‚ÇÄ ‚â§ t < q‚ÇÄ.‚Çà‚ÇÖ}, and ‚Ñ∞_test = {(u, v, t) : t ‚â• q‚ÇÄ.‚Çà‚ÇÖ}, where q_p denotes the p-th quantile of all timestamps. This ensures the model is trained on historical data and evaluated exclusively on future predictions, mirroring real-world deployment scenarios.

**Evaluation Metrics.** We adopt a ranking-based evaluation framework rather than binary classification. For each test interaction (u, v, t) ‚àà ‚Ñ∞_test, we sample N = 100 negative nodes ùí©_u uniformly from ùí± \ {v}, compute scores s(u, v', t) for all v' ‚àà {v} ‚à™ ùí©_u, and determine the rank r of the true node v in descending order of scores. We report:

- **Mean Reciprocal Rank (MRR)**: MRR = 1/|‚Ñ∞_test| Œ£_(u,v,t)‚àà‚Ñ∞_test 1/r, measuring the average inverse rank of true links.
- **Recall@K**: Recall@K = |{(u,v,t) ‚àà ‚Ñ∞_test : r ‚â§ K}| / |‚Ñ∞_test|, quantifying the fraction of true links retrieved in the top-K predictions. We report K ‚àà {10, 50, 1000}.
- **Average Precision (AP)**: The area under the precision-recall curve, robust to class imbalance.
- **AUC-ROC**: The area under the receiver operating characteristic curve, measuring binary classification performance.

These metrics provide complementary perspectives: MRR and Recall@K evaluate ranking quality relevant to recommendation systems, while AP and AUC enable comparison with prior work on link prediction [Hamilton et al., 2017; Xu et al., 2020]. Given the extreme class imbalance in our CrunchBase dataset (0.03% positive rate), we report the improvement factor over a random baseline, which achieves Recall@1000 = 0.6%.

---

## Version 5 : En Fran√ßais Acad√©mique (~250 mots)

### Pour rapport de Master/Th√®se en fran√ßais

**Protocole de Validation Temporelle.** Afin de respecter la causalit√© temporelle inh√©rente aux graphes dynamiques, nous adoptons un protocole de validation strictement chronologique. Les interactions sont partitionn√©es selon leurs timestamps : 70% des interactions les plus anciennes constituent l'ensemble d'entra√Ænement, 15% servent √† la validation des hyperparam√®tres, et les 15% restantes, les plus r√©centes, forment l'ensemble de test. Cette strat√©gie garantit que le mod√®le pr√©dit exclusivement des √©v√©nements futurs, √©vitant ainsi toute fuite d'information (*temporal leakage*) et simulant fid√®lement un sc√©nario de d√©ploiement r√©el.

**M√©triques d'√âvaluation.** Plut√¥t qu'une simple classification binaire, nous √©valuons le mod√®le selon une approche de **ranking** plus pertinente pour les syst√®mes de recommandation. Pour chaque lien test (u, v, t), le mod√®le classe le n≈ìud destination r√©el v parmi 100 candidats n√©gatifs √©chantillonn√©s al√©atoirement. Nous mesurons le **Mean Reciprocal Rank (MRR)**, qui quantifie la position moyenne du vrai lien dans ce classement, ainsi que le **Recall@K**, repr√©sentant la proportion de vrais liens retrouv√©s dans les top-K pr√©dictions (K ‚àà {10, 50, 1000}). Nous compl√©tons par l'**Average Precision (AP)** et l'**AUC-ROC**, m√©triques standard de pr√©diction de liens. Dans notre jeu de donn√©es CrunchBase, caract√©ris√© par un fort d√©s√©quilibre (0,03% de liens positifs), un classement al√©atoire atteindrait un Recall@1000 de 0,6%. Nos r√©sultats sont donc syst√©matiquement rapport√©s avec le facteur d'am√©lioration par rapport √† cette baseline, fournissant ainsi une mesure intuitive de la performance du mod√®le.

---

## Version 6 : Condens√©e pour Abstract/R√©sum√© (~80 mots)

We evaluate our TGN model using temporal validation, where data is split chronologically into train (70%), validation (15%), and test (15%) sets, ensuring predictions are made exclusively on future interactions. Performance is measured using ranking-based metrics: Mean Reciprocal Rank (MRR), Recall@K (K ‚àà {10, 50, 1000}), Average Precision (AP), and AUC-ROC. Given the extreme class imbalance (0.03% positive links), we report improvement factors over a random baseline to contextualize results.

---

## Recommandations d'Utilisation

| Section du Rapport | Version Recommand√©e | Pourquoi |
|-------------------|---------------------|----------|
| **Abstract/R√©sum√©** | Version 6 (Condens√©e) | Tr√®s concis, capture l'essentiel |
| **Introduction** | Version 1 (Courte) | Introduit la m√©thodologie sans d√©tails |
| **M√©thodologie** | Version 2 (Moyenne) ou 3 (Longue) | D√©tails suffisants sans surcharger |
| **Article Scientifique** | Version 4 (Formelle) | Notation math√©matique, r√©f√©rences |
| **Rapport Master/Th√®se FR** | Version 5 (Fran√ßais) | Style acad√©mique fran√ßais |
| **Supplementary Material** | Version 3 (Longue) | Tous les d√©tails techniques |

---

## √âl√©ments √† Personnaliser

Selon vos r√©sultats finaux, remplacez les valeurs suivantes :

```
[VALEURS ACTUELLES - √Ä METTRE √Ä JOUR]

- AP: 0.35 ‚Üí [votre valeur apr√®s Focal/HAR]
- AUC: 0.75 ‚Üí [votre valeur]
- MRR: 0.02 ‚Üí [votre valeur]
- Recall@10: 0.00 ‚Üí [votre valeur]
- Recall@50: 0.05 ‚Üí [votre valeur]
- Recall@1000: 0.077 ‚Üí [votre valeur]
- Baseline al√©atoire: 0.6% ‚Üí [confirmer avec votre dataset final]
- Am√©lioration vs baseline: 13x ‚Üí [recalculer]
```

---

## Citations √† Ajouter (Optionnel)

Si vous utilisez la Version 4 (formelle), ajoutez ces r√©f√©rences :

```bibtex
@article{rossi2020temporal,
  title={Temporal graph networks for deep learning on dynamic graphs},
  author={Rossi, Emanuele and Chamberlain, Ben and Frasca, Fabrizio and Eynard, Danica and Monti, Federico and Bronstein, Michael},
  journal={ICML Workshop on Graph Representation Learning},
  year={2020}
}

@inproceedings{kumar2020predicting,
  title={Predicting dynamic embedding trajectory in temporal interaction networks},
  author={Kumar, Srijan and Zhang, Xikun and Leskovec, Jure},
  booktitle={KDD},
  year={2020}
}

@inproceedings{hamilton2017inductive,
  title={Inductive representation learning on large graphs},
  author={Hamilton, Will and Ying, Zhitao and Leskovec, Jure},
  booktitle={NeurIPS},
  year={2017}
}

@article{xu2020tgat,
  title={Inductive representation learning on temporal graphs},
  author={Xu, Da and Ruan, Chuanwei and Korpeoglu, Evren and Kumar, Sushant and Achan, Kannan},
  journal={ICLR},
  year={2020}
}
```

---

## Figure Sugg√©r√©e

Pour accompagner le texte, cr√©ez une figure montrant :

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Timeline des Interactions (CrunchBase)                 ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ                                                          ‚îÇ
‚îÇ  [‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà TRAIN 70% ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà] [VAL] [TEST]    ‚îÇ
‚îÇ  2000              2010            2018 2020      2023   ‚îÇ
‚îÇ                                      ‚Üë    ‚Üë         ‚Üë    ‚îÇ
‚îÇ                                      ‚îÇ    ‚îÇ         ‚îÇ    ‚îÇ
‚îÇ                              Entra√Ænement ‚îÇ    √âvaluation‚îÇ
‚îÇ                                           ‚îÇ              ‚îÇ
‚îÇ                                    Validation            ‚îÇ
‚îÇ                                                          ‚îÇ
‚îÇ  Pr√©diction: Investissements 2020-2023                  ‚îÇ
‚îÇ  bas√©e sur: Historique 2000-2018                        ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## Exemple d'Int√©gration Compl√®te

Voici comment int√©grer le paragraphe dans votre structure de rapport :

```markdown
## 4. M√©thodologie Exp√©rimentale

### 4.1 Architecture du Mod√®le
[Votre description du TGN...]

### 4.2 Strat√©gie de Validation

[INS√âRER VERSION 2 OU 3 ICI]

### 4.3 Fonction de Perte
Pour g√©rer le d√©s√©quilibre de classes extr√™me (0.03% de liens positifs),
nous comparons trois fonctions de perte : Binary Cross-Entropy (BCE) comme
baseline, Focal Loss pour...

### 4.4 Hyperparam√®tres
[Vos hyperparam√®tres...]

## 5. R√©sultats

### 5.1 Performance des Fonctions de Perte
Le tableau 1 pr√©sente les r√©sultats de validation pour les trois
fonctions de perte test√©es...

[TABLE avec r√©sultats]
```

---

## Checklist pour Votre Rapport

- [ ] Expliquer le split temporel (70/15/15)
- [ ] Justifier pourquoi ranking > classification binaire
- [ ] D√©finir MRR avec formule math√©matique
- [ ] D√©finir Recall@K avec formule
- [ ] Mentionner AP et AUC pour comparaison
- [ ] Donner baseline al√©atoire (0.6%)
- [ ] Calculer am√©lioration vs baseline
- [ ] Ajouter figure du timeline temporel
- [ ] Citer au moins 2-3 r√©f√©rences pertinentes

Bonne chance avec votre rapport ! üéì
