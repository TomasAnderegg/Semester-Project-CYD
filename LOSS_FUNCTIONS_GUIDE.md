# Guide des Loss Functions : BCE vs Focal Loss vs HAR Loss

## Vue d'Ensemble

Votre syst√®me TGN supporte maintenant **3 loss functions** pour l'entra√Ænement :

| Loss Function | Probl√®me Cibl√© | Quand l'Utiliser |
|---------------|----------------|------------------|
| **BCE (Baseline)** | Aucun (standard) | Baseline de r√©f√©rence |
| **Focal Loss** | D√©s√©quilibre de classes extr√™me | Dataset avec peu de positifs |
| **HAR Loss** | Degree bias dans les graphes | Favoriser les n≈ìuds √† faible degr√© |

---

## 1. Binary Cross-Entropy (BCE) - Baseline

### Description

La loss function standard pour la classification binaire.

```python
BCE = -[y * log(p) + (1-y) * log(1-p)]
```

### Avantages
- Simple et bien comprise
- Rapide (pas d'overhead)
- Bonne baseline de r√©f√©rence

### Inconv√©nients
- Sensible au d√©s√©quilibre de classes
- Biais√©e vers les n≈ìuds populaires (high-degree)
- Les exemples faciles dominent l'entra√Ænement

### Utilisation

```bash
# Option 1: Par d√©faut (sans flag)
python train_self_supervised.py \
  --data crunchbase \
  --use_memory \
  --prefix tgn-bce \
  --n_epoch 50

# Option 2: Explicite (pour clart√©)
python train_self_supervised.py \
  --data crunchbase \
  --use_memory \
  --prefix tgn-bce-baseline \
  --n_epoch 50
```

**Note :** Si aucun flag `--use_focal_loss` ou `--use_har_loss` n'est sp√©cifi√©, BCE est utilis√©e par d√©faut.

---

## 2. Focal Loss - Pour D√©s√©quilibre de Classes

### Description

Focal Loss r√©duit l'importance des exemples bien class√©s (easy examples) pour se concentrer sur les exemples difficiles.

```python
FL(p_t) = -Œ±_t * (1 - p_t)^Œ≥ * log(p_t)
```

**Param√®tres :**
- **gamma (Œ≥)** : Focusing parameter (d√©faut: 2.0)
  - Œ≥=0 ‚Üí √©quivalent √† BCE
  - Œ≥=2 ‚Üí r√©duction forte des easy examples
  - Œ≥=5 ‚Üí tr√®s agressif

- **alpha (Œ±)** : Poids pour la classe positive (d√©faut: 0.25)
  - Œ±=0.25 ‚Üí classe positive a un poids de 25%
  - Œ±=0.5 ‚Üí poids √©gal entre positifs et n√©gatifs

### Quand l'Utiliser

‚úÖ **Votre cas (RECOMMAND√â) :**
```
Dataset: 52 positifs sur 170,742 paires (0.03%)
‚Üí D√©s√©quilibre extr√™me
‚Üí Focal Loss est id√©al
```

‚úÖ **Autres cas :**
- Ratio positifs/n√©gatifs < 1%
- M√©diane des probabilit√©s pour vrais liens < 0.3
- Besoin de d√©tecter des patterns rares

‚ùå **NE PAS utiliser si :**
- Dataset √©quilibr√© (ratio ~50/50)
- Tous les exemples sont d√©j√† difficiles

### Utilisation

```bash
# Configuration par d√©faut (recommand√©e)
python train_self_supervised.py \
  --data crunchbase \
  --use_memory \
  --use_focal_loss \
  --focal_alpha 0.25 \
  --focal_gamma 2.0 \
  --prefix tgn-focal \
  --n_epoch 50

# Pour d√©s√©quilibre TR√àS extr√™me
python train_self_supervised.py \
  --data crunchbase \
  --use_memory \
  --use_focal_loss \
  --focal_alpha 0.1 \
  --focal_gamma 2.0 \
  --prefix tgn-focal-aggressive \
  --n_epoch 50

# Pour focalisation plus forte
python train_self_supervised.py \
  --data crunchbase \
  --use_memory \
  --use_focal_loss \
  --focal_alpha 0.25 \
  --focal_gamma 5.0 \
  --prefix tgn-focal-gamma5 \
  --n_epoch 50
```

### R√©sultats Attendus

**Avant (BCE) :**
```
M√©diane probabilit√© vrais liens: 0.04
Recall@1000: 7.7%
```

**Apr√®s (Focal Loss) :**
```
M√©diane probabilit√© vrais liens: 0.25-0.40 (esp√©r√©)
Recall@1000: 15-25% (esp√©r√©)
‚Üí Am√©lioration 2-3x
```

---

## 3. HAR Loss - Pour Degree Bias

### Description

HAR (Hardness Adaptive Reweighted) Loss combat le degree bias en donnant plus de poids aux n≈ìuds √† faible degr√©.

```python
HAR_loss = sum_i [ w(src_i) * w(dst_i) * L_contrastive(i) ]

o√π w(node) = degree(node)^(-alpha)
```

**Param√®tres :**
- **temperature** : Temp√©rature pour contrastive loss (d√©faut: 0.07)
  - Plus basse ‚Üí discrimination plus stricte
  - Plus haute ‚Üí plus permissive

- **alpha** : Exposant de reweighting par degr√© (d√©faut: 0.5)
  - Œ±=0 ‚Üí pas de correction (√©quivalent √† ignorer le degr√©)
  - Œ±=0.5 ‚Üí correction mod√©r√©e (RECOMMAND√â)
  - Œ±=1.0 ‚Üí correction forte

### M√©canisme

```python
# Exemple avec alpha = 0.5
N≈ìud haut degr√© (100) ‚Üí weight = 100^(-0.5) = 0.10  ‚Üê R√©duit
N≈ìud bas degr√© (2)    ‚Üí weight = 2^(-0.5)   = 0.71  ‚Üê Augment√©

‚Üí Les n≈ìuds √† faible degr√© contribuent 7x plus √† la loss !
```

### Quand l'Utiliser

‚úÖ **Utilisez HAR Loss si :**
- Vous voulez identifier des **startups √©mergentes** (low-degree)
- Vous avez d√©tect√© un **degree bias** (corr√©lation degr√©-performance > 0.5)
- Votre mod√®le ignore les n≈ìuds rares
- Vous cherchez des "p√©pites" avant qu'elles deviennent populaires

‚ùå **NE PAS utiliser si :**
- Vous ciblez surtout les n≈ìuds populaires
- Pas de degree bias d√©tect√© (performance uniforme par degr√©)
- Les low-degree nodes sont peu informatifs (trop de bruit)

### Utilisation

```bash
# Configuration par d√©faut (recommand√©e)
python train_self_supervised.py \
  --data crunchbase \
  --use_memory \
  --use_har_loss \
  --har_temperature 0.07 \
  --har_alpha 0.5 \
  --prefix tgn-har \
  --n_epoch 50

# Correction degree bias plus forte
python train_self_supervised.py \
  --data crunchbase \
  --use_memory \
  --use_har_loss \
  --har_temperature 0.07 \
  --har_alpha 0.75 \
  --prefix tgn-har-strong \
  --n_epoch 50

# Temp√©rature plus √©lev√©e (plus permissif)
python train_self_supervised.py \
  --data crunchbase \
  --use_memory \
  --use_har_loss \
  --har_temperature 0.15 \
  --har_alpha 0.5 \
  --prefix tgn-har-temp015 \
  --n_epoch 50
```

### Diagnostic : Avez-vous un Degree Bias ?

**Apr√®s entra√Ænement avec BCE/Focal, analysez :**

```python
import pandas as pd
import numpy as np

# Charger pr√©dictions
df = pd.read_csv('predictions.csv')

# Calculer degr√©s
startup_degrees = {}  # {startup_id: degree}
for src, dst in zip(train_data.sources, train_data.destinations):
    startup_degrees[src] = startup_degrees.get(src, 0) + 1

df['degree'] = df['startup_id'].map(startup_degrees)

# Grouper par quartiles de degr√©
df['degree_quartile'] = pd.qcut(df['degree'], q=4, labels=['Q1-Low', 'Q2', 'Q3', 'Q4-High'])

# Comparer performance
performance = df.groupby('degree_quartile').agg({
    'probability': 'mean',
    'is_correct': 'mean'
})

print(performance)
```

**Interpr√©tation :**

```
# SI DEGREE BIAS PR√âSENT:
degree_quartile  probability  is_correct
Q1-Low           0.15         0.45        ‚Üê Mauvais
Q2               0.35         0.62
Q3               0.58         0.78
Q4-High          0.82         0.91        ‚Üê Excellent

‚Üí HAR Loss recommand√©e

# SI PAS DE DEGREE BIAS:
degree_quartile  probability  is_correct
Q1-Low           0.68         0.83
Q2               0.71         0.85
Q3               0.69         0.84
Q4-High          0.72         0.86

‚Üí HAR Loss pas n√©cessaire
```

---

## Comparaison Compl√®te

### Tableau R√©capitulatif

| Aspect | BCE | Focal Loss | HAR Loss |
|--------|-----|------------|----------|
| **D√©s√©quilibre classes** | ‚ùå Mauvais | ‚úÖ Excellent | ‚ö†Ô∏è Moyen |
| **Degree bias** | ‚ùå Pas de correction | ‚ùå Pas de correction | ‚úÖ Corrige |
| **Exemples faciles** | Dominent | Ignor√©s | Selon degr√© |
| **Exemples difficiles** | Standard | Focalis√©s | + Focalis√©s si low-degree |
| **Overhead computationnel** | Baseline | +5% | +10% |
| **Complexit√©** | Simple | Simple | Mod√©r√©e |
| **Hyperparam√®tres** | 0 | 2 (alpha, gamma) | 2 (temperature, alpha) |

### Exemple Concret

**Sc√©nario : Pr√©dire investissement**

```
Startup A: "DeepMind" (degr√©=50, pattern √©vident)
‚Üí Mod√®le pr√©dit p=0.95 (facile)

BCE:        loss = 0.05
Focal:      loss = 0.0025    ‚Üê Ignor√© (facile)
HAR:        loss = 0.007     ‚Üê R√©duit (haut degr√©)

----

Startup B: "StealthQuantum" (degr√©=2, pattern difficile)
‚Üí Mod√®le pr√©dit p=0.25 (difficile)

BCE:        loss = 1.39
Focal:      loss = 0.78      ‚Üê Focalis√© (difficile)
HAR:        loss = 0.99      ‚Üê TR√àS focalis√© (bas degr√© + difficile)
```

---

## Strat√©gie de Comparaison Recommand√©e

### Phase 1 : Baseline

```bash
# Entra√Æner avec BCE (baseline)
python train_self_supervised.py \
  --data crunchbase \
  --use_memory \
  --prefix tgn-bce \
  --n_epoch 50
```

### Phase 2 : Focal Loss (Votre Priorit√©)

```bash
# Entra√Æner avec Focal Loss
python train_self_supervised.py \
  --data crunchbase \
  --use_memory \
  --use_focal_loss \
  --focal_alpha 0.25 \
  --focal_gamma 2.0 \
  --prefix tgn-focal \
  --n_epoch 50
```

### Phase 3 : HAR Loss (Si Degree Bias)

```bash
# Entra√Æner avec HAR Loss
python train_self_supervised.py \
  --data crunchbase \
  --use_memory \
  --use_har_loss \
  --har_temperature 0.07 \
  --har_alpha 0.5 \
  --prefix tgn-har \
  --n_epoch 50
```

### Phase 4 : √âvaluation

```bash
# √âvaluer tous les mod√®les
for model in bce focal har; do
  python temporal_validation_diagnostic.py \
    --data crunchbase \
    --model_path saved_models/tgn-${model}-crunchbase.pth \
    --use_memory \
    --auto_detect_params
done
```

### Phase 5 : Comparaison

```python
import pandas as pd

# Charger r√©sultats
results = []
for model in ['bce', 'focal', 'har']:
    df = pd.read_csv(f'results/tgn-{model}-results.csv')
    df['model'] = model
    results.append(df)

results_df = pd.concat(results)

# Comparer m√©triques
comparison = results_df.groupby('model').agg({
    'recall@1000': 'mean',
    'precision@1000': 'mean',
    'median_rank_true_links': 'median'
})

print(comparison)
```

---

## M√©triques √† Surveiller

### Pour Focal Loss

| M√©trique | Baseline (BCE) | Cible (Focal) |
|----------|----------------|---------------|
| M√©diane prob vrais liens | 0.04 | 0.25-0.40 |
| Recall@1000 | 7.7% | 15-25% |
| Rang m√©dian vrais liens | 6,609 | <5,000 |

### Pour HAR Loss

| M√©trique | Baseline | Cible (HAR) |
|----------|----------|-------------|
| Performance low-degree | 0.45 | 0.70+ |
| Performance high-degree | 0.91 | 0.80-0.90 (peut baisser) |
| Diversit√© pr√©dictions | Faible | √âlev√©e |

---

## Troubleshooting

### Probl√®me : Focal Loss donne de moins bons r√©sultats que BCE

**Causes possibles :**
1. Gamma trop √©lev√© (mod√®le ignore trop d'exemples)
2. Alpha mal calibr√©
3. Dataset pas assez d√©s√©quilibr√©

**Solutions :**
```bash
# R√©duire gamma
--focal_gamma 1.0  # Au lieu de 2.0

# Ajuster alpha
--focal_alpha 0.5  # Au lieu de 0.25
```

### Probl√®me : HAR Loss ne converge pas

**Causes possibles :**
1. Alpha trop √©lev√© (correction trop agressive)
2. Temp√©rature trop basse
3. Degr√©s mal calcul√©s

**Solutions :**
```bash
# R√©duire alpha
--har_alpha 0.25  # Au lieu de 0.5

# Augmenter temp√©rature
--har_temperature 0.15  # Au lieu de 0.07
```

### Probl√®me : Pas d'am√©lioration avec HAR Loss

**Diagnostic :**
- V√©rifiez s'il y a vraiment un degree bias (voir section diagnostic)
- Si pas de degree bias ‚Üí HAR Loss n'est pas n√©cessaire
- Restez avec Focal Loss

---

## Combinaison Focal + HAR ?

**Actuellement NON support√©**, mais vous pouvez :

1. **Approche s√©quentielle :**
   ```bash
   # √âtape 1: Pr√©-entra√Æner avec Focal Loss
   python train_self_supervised.py \
     --use_focal_loss --prefix tgn-focal --n_epoch 30

   # √âtape 2: Fine-tuner avec HAR Loss
   python train_self_supervised.py \
     --use_har_loss --prefix tgn-har-finetune --n_epoch 20 \
     --load_checkpoint saved_models/tgn-focal-crunchbase.pth
   ```

2. **Impl√©menter Hybrid Loss** (n√©cessite d√©veloppement)

---

## R√©f√©rences

### Papers

1. **Focal Loss:**
   - Lin et al. (2017), "Focal Loss for Dense Object Detection"
   - https://arxiv.org/abs/1708.02002

2. **HAR Loss:**
   - Zhang et al. (2021), "Graph Contrastive Learning with Adaptive Augmentation"
   - Wang et al. (2022), "Debiasing Graph Neural Networks via Learning Disentangled Causal Substructure"

### Fichiers Code

- `focal_loss.py` : Impl√©mentation Focal Loss
- `har_loss.py` : Impl√©mentation HAR Loss
- `train_self_supervised.py` : Script d'entra√Ænement avec les 3 loss

---

## R√©sum√© : Quelle Loss Choisir ?

```
Votre Dataset: 0.03% positifs, probable degree bias

‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ RECOMMANDATION POUR VOUS :              ‚îÇ
‚îÇ                                         ‚îÇ
‚îÇ 1. Commencer avec FOCAL LOSS ‚úÖ         ‚îÇ
‚îÇ    ‚Üí R√©sout votre d√©s√©quilibre extr√™me ‚îÇ
‚îÇ                                         ‚îÇ
‚îÇ 2. Diagnostiquer degree bias           ‚îÇ
‚îÇ    ‚Üí Analyser performance par degr√©    ‚îÇ
‚îÇ                                         ‚îÇ
‚îÇ 3. Si degree bias d√©tect√©:             ‚îÇ
‚îÇ    ‚Üí Tester HAR LOSS                   ‚îÇ
‚îÇ                                         ‚îÇ
‚îÇ 4. Comparer les 3 approches            ‚îÇ
‚îÇ    ‚Üí Choisir la meilleure              ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

**Prochaine √©tape :** Lancer `python train_self_supervised.py --use_focal_loss` pour commencer ! üöÄ
