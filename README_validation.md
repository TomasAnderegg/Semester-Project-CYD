# Validation Temporelle - Documentation

## Vue d'ensemble

Ce module √©tend votre pipeline TGN-TechRank existant avec des **m√©triques de validation temporelle robustes** pour √©valuer la capacit√© du mod√®le √† pr√©dire les entreprises prometteuses **AVANT** qu'elles ne deviennent √©videntes.

### Principe

```
Timeline :
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚Üí
2018          2020          2022      temps
‚îÇ             ‚îÇ             ‚îÇ
‚îÇ‚óÑ‚îÄTraining‚îÄ‚îÄ‚ñ∫‚îÇ‚óÑValidation‚îÄ‚ñ∫‚îÇ

Question cl√© : Les entreprises class√©es en t√™te en 2020 (par TGN+TechRank)
               ont-elles R√âELLEMENT connu une croissance en 2020-2022?
```

## Installation

```bash
# Aucune nouvelle d√©pendance - utilise vos packages existants
pip install pandas numpy networkx scipy matplotlib seaborn
```

## Utilisation Rapide

### Option 1: Pipeline complet (recommand√©)

```python
from temporal_validation import run_temporal_validation_pipeline
import pandas as pd
import pickle

# 1. Charger les r√©sultats existants
df_delta = pd.read_csv('techrank_comparison/company_techrank_deltas.csv')

# 2. Charger les graphes
with open('B_train.pkl', 'rb') as f:
    B_train = pickle.load(f)
with open('B_test.pkl', 'rb') as f:
    B_test = pickle.load(f)

# 3. Lancer la validation
metrics = run_temporal_validation_pipeline(
    df_delta=df_delta,
    B_before=B_train,
    B_after=B_test,
    top_k_list=[10, 20, 50],
    growth_threshold=2.0,  # Doublement du degr√©
    prediction_horizon_days=730,  # 2 ans
    output_dir='validation_results',
    create_plots=True,
    export_latex=True
)

# 4. R√©sultats
print(f"Precision@20: {metrics.precision_at_k[20]:.2%}")
print(f"Spearman œÅ: {metrics.spearman_rho:.3f}")
print(f"EDR@50: {metrics.edr_at_k[50]:.2%}")
print(f"Lift@20: {metrics.lift_at_k[20]:.2f}x")
```

### Option 2: M√©triques seulement (sans plots)

```python
from temporal_validation import compute_validation_metrics

metrics = compute_validation_metrics(
    df_delta=df_delta,
    B_before=B_train,
    B_after=B_test,
    top_k_list=[10, 20, 50],
    growth_threshold=2.0
)
```

## M√©triques Calcul√©es

### 1. Precision@K

**D√©finition**: Pour les K entreprises les mieux class√©es par le mod√®le, combien ont R√âELLEMENT eu une croissance positive?

```python
Precision@K = (Nb d'entreprises top-K avec croissance) / K
```

**Interpr√©tation**:
- `Precision@20 = 0.70` ‚Üí 14/20 entreprises du top-20 ont effectivement grandi
- ‚úÖ **Bon**: > 0.6
- ‚ö†Ô∏è **Mod√©r√©**: 0.3 - 0.6
- ‚ùå **Faible**: < 0.3

### 2. Rank Correlation (Spearman œÅ)

**D√©finition**: Corr√©lation entre le classement pr√©dit et la croissance r√©elle observ√©e.

```python
œÅ = spearmanr(predicted_ranks, actual_growth)
```

**Interpr√©tation**:
- `œÅ > 0.7` ‚Üí Corr√©lation forte ‚≠ê
- `œÅ > 0.4` ‚Üí Corr√©lation mod√©r√©e ‚úì
- `œÅ > 0.2` ‚Üí Corr√©lation faible
- `œÅ < 0.2` ‚Üí Pas de corr√©lation ‚ùå

**Exemple**: `œÅ = 0.58, p < 0.001` ‚Üí Corr√©lation mod√©r√©e et hautement significative

### 3. Early Detection Rate (EDR@K)

**D√©finition**: Parmi les entreprises ayant connu une **forte croissance** (doublement), combien √©taient dans le top-K?

```python
EDR@K = (Nb d√©tect√©es dans top-K) / (Total entreprises forte croissance)
```

**Interpr√©tation**:
- `EDR@50 = 0.45` ‚Üí Le mod√®le a d√©tect√© 45% des entreprises √† forte croissance dans le top-50

### 4. Lift Score

**D√©finition**: Am√©lioration par rapport √† une s√©lection al√©atoire.

```python
Lift@K = (Taux de succ√®s mod√®le) / (Taux de succ√®s baseline)
```

**Interpr√©tation**:
- `Lift@20 = 8.5x` ‚Üí Le mod√®le est 8.5√ó meilleur que le hasard
- ‚úÖ **Excellent**: > 5x
- ‚úì **Bon**: 2-5x
- ‚ö†Ô∏è **Faible**: < 2x

### 5. Lead Time

**D√©finition**: D√©lai moyen entre la pr√©diction et l'observation r√©elle de la croissance.

**Exemple**: `Lead time = 730 jours (24 mois)` ‚Üí Le mod√®le pr√©dit 2 ans √† l'avance

## Structure des Fichiers G√©n√©r√©s

```
validation_results/
‚îú‚îÄ‚îÄ validation_metrics.json           # Toutes les m√©triques (r√©utilisable)
‚îú‚îÄ‚îÄ validation_report.tex             # Rapport LaTeX pr√™t √† inclure
‚îú‚îÄ‚îÄ precision_at_k_comparison.png     # Model vs Baselines
‚îú‚îÄ‚îÄ predicted_vs_actual_scatter.png   # Scatter plot avec corr√©lation
‚îú‚îÄ‚îÄ top_20_companies_validation.png   # Top-20 avec croissance r√©elle
‚îî‚îÄ‚îÄ edr_lift_summary.png              # EDR et Lift visualis√©s
```

## Workflow Complet

### √âtape 1: Pr√©parer les donn√©es

```python
# Votre code existant (d√©j√† fait!)
from data.bipartite_investor_comp import main, temporal_split_graph

# Split temporel (d√©j√† impl√©ment√© dans votre code)
B_train, B_val, B_test, max_train_time, max_val_time = temporal_split_graph(
    B_full,
    train_ratio=0.85,
    val_ratio=0.0
)
```

### √âtape 2: Calculer TechRank AVANT et APR√àS

```python
# Votre code existant (TechRank_Comparison.py)
from code.TechRank import run_techrank

# TechRank sur graphe AVANT (train)
_, df_companies_before = run_techrank(
    B=B_train,
    dict_investors=dict_inv_train,
    dict_comp=dict_comp_train,
    alpha=0.8,
    beta=-0.6
)

# TechRank sur graphe APR√àS (test = "future r√©el")
_, df_companies_after = run_techrank(
    B=B_test,
    dict_investors=dict_inv_test,
    dict_comp=dict_comp_test,
    alpha=0.8,
    beta=-0.6
)

# Calculer les deltas (d√©j√† impl√©ment√©!)
from TechRank_Comparison import analyze_company_deltas

df_delta, df_promising = analyze_company_deltas(
    df_companies_before,
    df_companies_after,
    threshold=0.01,
    top_k=50
)
```

### √âtape 3: Validation temporelle (NOUVEAU)

```python
from temporal_validation import run_temporal_validation_pipeline

metrics = run_temporal_validation_pipeline(
    df_delta=df_delta,
    B_before=B_train,
    B_after=B_test,
    prediction_horizon_days=(max_val_time - max_train_time).days
)
```

## Exemples de R√©sultats

### R√©sultat Excellent

```
üìä VALIDATION SUMMARY
‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ
üéØ PRECISION@K:
   @10: 0.800 (80.0%)
   @20: 0.750 (75.0%)
   @50: 0.660 (66.0%)

üìà RANK CORRELATION:
   Spearman œÅ: 0.6234 (p=0.0001)
   ‚≠ê Highly significant correlation!

üîç EARLY DETECTION RATE (‚â•2.0x growth):
   @50: 0.550 (11/20 high-growth companies detected)

üìä LIFT SCORE:
   @20: 9.38x (baseline: 0.08)

‚è±Ô∏è LEAD TIME:
   Average: 730 days (24.3 months)
```

**Interpr√©tation**: Le mod√®le d√©tecte efficacement les entreprises prometteuses 2 ans √† l'avance, avec un taux de succ√®s 9√ó sup√©rieur au hasard.

### R√©sultat Mod√©r√©

```
üéØ PRECISION@K:
   @20: 0.450 (45.0%)

üìà RANK CORRELATION:
   Spearman œÅ: 0.3521 (p=0.0123)
   ‚úì Significant correlation

üìä LIFT SCORE:
   @20: 3.75x
```

**Interpr√©tation**: Le mod√®le capture certains signaux pr√©dictifs mais pourrait b√©n√©ficier d'am√©liorations (features, hyperparam√®tres).

## Bonnes Pratiques

### 1. Validation stricte temporelle

‚úÖ **CORRECT**: Split strict par date
```python
train_end = "2020-12-31"
test_start = "2021-01-01"
# Aucune donn√©e du futur dans l'entra√Ænement
```

‚ùå **INCORRECT**: Split al√©atoire
```python
train_test_split(random_state=42)  # Leakage temporel!
```

### 2. Interpr√©tation des m√©triques

- **Precision@K** ‚Üí Qualit√© des top-K pr√©dictions (most important)
- **Spearman œÅ** ‚Üí Qualit√© globale du classement
- **EDR@K** ‚Üí Capacit√© √† d√©tecter les "p√©pites"
- **Lift** ‚Üí Am√©lioration vs baselines

### 3. Choix du seuil de croissance

```python
# Tester plusieurs seuils
for threshold in [1.5, 2.0, 2.5, 3.0]:
    metrics = compute_validation_metrics(..., growth_threshold=threshold)
    print(f"Threshold {threshold}x: EDR@50={metrics.edr_at_k[50]:.2%}")
```

Recommandation:
- **2.0x** (doublement) ‚Üí Standard, √©quilibr√©
- **1.5x** ‚Üí Plus permissif (plus d'entreprises qualifi√©es)
- **3.0x** ‚Üí Tr√®s strict (seulement croissances exceptionnelles)

## Comparaison avec d'autres Approches

### vs Random Baseline
S√©lection al√©atoire de K entreprises.

### vs Degree Baseline
Classement na√Øf par degr√© initial seulement (sans TGN, sans TechRank).

**Le mod√®le doit TOUJOURS surpasser les deux baselines.**

## Int√©gration avec votre Rapport LaTeX

Le fichier `validation_report.tex` est pr√™t √† inclure:

```latex
\section{R√©sultats}

\input{validation_results/validation_report.tex}

\begin{figure}[h]
    \centering
    \includegraphics[width=0.8\textwidth]{validation_results/precision_at_k_comparison.png}
    \caption{Comparaison des performances: Mod√®le vs Baselines}
\end{figure}
```

## D√©pannage

### Probl√®me: Corr√©lation faible (œÅ < 0.2)

**Causes possibles**:
1. Features de n≈ìuds insuffisantes (vecteurs z√©ro)
2. Hyperparam√®tres TGN non optimis√©s
3. Param√®tres TechRank (Œ±, Œ≤) inadapt√©s

**Solutions**:
```python
# 1. Enrichir les features
# Ajouter descriptions textuelles (BERT), m√©tadonn√©es

# 2. Optimiser TGN
# Sweep sur num_layers, memory_dim, etc.

# 3. Tester diff√©rents Œ±, Œ≤
for alpha in [0.0, 0.3, 0.8]:
    for beta in [-5.0, -2.0, -0.6]:
        # Recalculer TechRank et √©valuer
```

### Probl√®me: Precision@20 faible (< 0.4)

**Diagnostic**:
```python
# Analyser les faux positifs
top_20 = df_delta.nlargest(20, 'techrank_delta')
false_positives = top_20[top_20['degree_growth'] <= 0]
print(false_positives[['final_configuration', 'techrank_delta', 'degree_before']])
```

**V√©rifier**:
- Les entreprises ont-elles un degr√© initial trop faible? ‚Üí Filtrer par `degree_before > 2`
- Probl√®me de hard negative mining? ‚Üí Am√©liorer le sampling TGN

### Probl√®me: "FileNotFoundError: df_delta.csv"

**Solution**: Lancer d'abord votre pipeline existant:
```bash
python TechRank_Comparison.py --data crunchbase --alpha 0.8 --beta -0.6 --plot
```

Puis la validation:
```bash
python -c "from temporal_validation import run_temporal_validation_pipeline; ..."
```

## API Reference

### Classes

#### `ValidationMetrics`
Dataclass contenant toutes les m√©triques calcul√©es.

**Attributs**:
- `precision_at_k: Dict[int, float]`
- `spearman_rho: float`
- `spearman_p_value: float`
- `edr_at_k: Dict[int, float]`
- `lift_at_k: Dict[int, float]`
- `avg_lead_time_days: float`

**M√©thodes**:
- `to_dict() -> Dict`: Convertit en dictionnaire
- `save_json(filepath)`: Sauvegarde en JSON

### Fonctions

#### `compute_validation_metrics()`
Calcule toutes les m√©triques de validation.

**Args**:
- `df_delta (pd.DataFrame)`: DataFrame avec deltas TechRank
- `B_before (nx.Graph)`: Graphe initial
- `B_after (nx.Graph)`: Graphe futur r√©el
- `top_k_list (List[int])`: Liste des K (d√©faut: [10, 20, 50])
- `growth_threshold (float)`: Seuil de forte croissance (d√©faut: 2.0)
- `prediction_horizon_days (float)`: Horizon en jours

**Returns**:
- `ValidationMetrics`

#### `create_validation_plots()`
G√©n√®re toutes les visualisations.

**Args**:
- `df_delta (pd.DataFrame)`
- `metrics (ValidationMetrics)`
- `save_dir (str)`: R√©pertoire de sortie
- `top_k_viz (int)`: Nombre d'entreprises √† visualiser (d√©faut: 20)

#### `generate_latex_report()`
G√©n√®re un rapport LaTeX.

**Args**:
- `metrics (ValidationMetrics)`
- `output_path (str)`: Chemin du fichier .tex

**Returns**:
- `str`: Contenu LaTeX

## FAQ

**Q: Quelle est la diff√©rence avec les m√©triques TGN standard (AUROC, AP)?**

A: Les m√©triques TGN mesurent la capacit√© √† distinguer vrais/faux liens. La validation temporelle mesure si les entreprises bien class√©es connaissent R√âELLEMENT une croissance future. C'est une validation business, pas seulement technique.

**Q: Pourquoi Precision@K et pas seulement AUROC?**

A: En pratique, on ne regarde que le top-K (ex: top-20 entreprises). Precision@K mesure directement l'utilit√© business.

**Q: Comment interpr√©ter un Spearman œÅ = 0.5?**

A: Corr√©lation mod√©r√©e. Le mod√®le capture des patterns pr√©dictifs mais pas parfaitement. Chercher √† am√©liorer les features ou hyperparam√®tres.

**Q: EDR@50 = 0.3, c'est bon?**

A: D√©pend du contexte. Si seulement 10 entreprises ont eu une forte croissance, d√©tecter 3/10 (30%) est d√©j√† utile. Comparer avec le Lift pour contextualiser.

**Q: Mon mod√®le a Precision@20 = 0.2, que faire?**

A:
1. V√©rifier que le split temporel est correct (pas de leakage)
2. Analyser les faux positifs (pourquoi sont-ils mal pr√©dits?)
3. Enrichir les features de n≈ìuds
4. Optimiser les hyperparam√®tres (TGN + TechRank)
5. Tester d'autres architectures (GCN, GraphSAGE)

## Citation

Si vous utilisez ce module dans vos travaux, merci de citer:

```bibtex
@misc{temporal_validation_tgn,
  author = {Your Name},
  title = {Temporal Validation for TGN-TechRank Disruption Detection},
  year = {2025},
  publisher = {EPFL - CYD Campus},
  howpublished = {\url{https://github.com/...}}
}
```

## Support

Pour toute question:
- Issues GitHub: https://github.com/.../issues
- Email: your.email@epfl.ch

## License

MIT License - Voir LICENSE file
